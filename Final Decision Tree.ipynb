{
 "metadata": {
  "name": "",
  "signature": "sha256:42915143628c1c97e890d3c5a899a3ed4b81c062c353851f33a869d9df8fd190"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import (tree, ensemble, metrics, dummy)\n",
      "from sklearn.linear_model import Lasso\n",
      "\n",
      "from galaxy_data import GalaxyData\n",
      "import evaluate\n",
      "import feature_extraction\n",
      "import matplotlib.pyplot as plt \n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from multiprocessing import Pool \n",
      "from operator import itemgetter "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Running without denoise_tv_chambolle\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = GalaxyData(feature_extraction.hog_features, scale_features=False)\n",
      "(X_train, y_train, X_validate, y_validate) = data.split_training_and_validation_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "RuntimeError",
       "evalue": "Cannot find input directory: ../../data/proc_images/",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-2-008991a28ed2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGalaxyData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhog_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_training_and_validation_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/jeffrey/Galaxy-Zoo-kaggle/galaxy_data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, feature_extraction_func, scale_features, lle)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_restricted_universe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestricted_universe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/jeffrey/Galaxy-Zoo-kaggle/galaxy_data.py\u001b[0m in \u001b[0;36mfolder_setup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \"\"\"\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_DIRECTORY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot find input directory: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mINPUT_DIRECTORY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mRuntimeError\u001b[0m: Cannot find input directory: ../../data/proc_images/"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_errors(input_data):\n",
      "    (values, X_train, y_train, X_validate, y_validate) = input_data\n",
      "    clf = tree.DecisionTreeRegressor(min_samples_split=values)\n",
      "    #clf = ensemble.RandomForestRegressor(max_features='log2', min_samples_split=values)\n",
      "    clf = ensemble.RandomForestRegressor(max_features='log2', n_estimators=values)\n",
      "    clf.fit(X_train, y_train)\n",
      "    validate_errors = evaluate.get_errors_clf(clf, X_validate, y_validate)\n",
      "    training_errors = evaluate.get_errors_clf(clf, X_train, y_train)\n",
      "    return (validate_errors, training_errors)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Decision tree min_samples_split\n",
      "values = range(2, 10000, 100)\n",
      "\n",
      "# Random Forest min_samples_split\n",
      "#values = range(2, 1000, 1)\n",
      "\n",
      "# Random Forest n_estimators\n",
      "#values = range(1, 100)\n",
      "\n",
      "pool = Pool()\n",
      "input_data_list = [(x, X_train, y_train, X_validate, y_validate) for x in values]\n",
      "output = np.array(pool.map(get_errors, input_data_list))\n",
      "validate_errors_list = output[:,0]\n",
      "training_errors_list = output[:,1]\n",
      "\n",
      "pool.close()\n",
      "pool.join()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "min_samples_split_list = range(2, 1000, 100)\n",
      "dr = dummy.DummyRegressor()\n",
      "dr.fit(X_train, y_train)\n",
      "base_line_error = evaluate.get_errors_clf(dr, X_validate, y_validate)\n",
      "base_line_error_list = [base_line_error for x in values]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def resolve_errors_lists(errors_list):\n",
      "    rmse = [x[0] for x in errors_list]\n",
      "    kl_divergence = [x[1] for x in errors_list]\n",
      "    kl_divergence = [x if x != float('Inf') else 0.25 for x in kl_divergence]\n",
      "    return (rmse, kl_divergence)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_data(values, validate_errors_list, training_errors_list, base_line_error_list):\n",
      "    # Setup error types\n",
      "    error_types = ['rmse', 'KL divergence']\n",
      "    validation_errors = resolve_errors_lists(validate_errors_list)\n",
      "    training_errors = resolve_errors_lists(training_errors_list)\n",
      "    base_line_errors = resolve_errors_lists(base_line_error_list)\n",
      "    \n",
      "    for (i, error_type) in enumerate(error_types):\n",
      "        plt.subplot(1, 2, i) \n",
      "        plt.plot(values, validation_errors[i], label='validation')\n",
      "        plt.plot(values, training_errors[i], label='training')\n",
      "        plt.plot(values, base_line_errors[i], label='baseline(mean)')\n",
      "        plt.plot()\n",
      "        plt.title('Training and Validation ' + error_type)\n",
      "        plt.legend(loc='right', bbox_to_anchor = (0.9, 0.3) )\n",
      "        plt.xlabel('number of trees')\n",
      "        plt.ylabel(error_type)\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_data(values, validate_errors_list, training_errors_list, base_line_error_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(min_rsme_value_index, min_rsme_value) = min(enumerate(validate_errors_list[:,0]), key=itemgetter(1))\n",
      "print('minimum rmse: ' + str(min_rsme_value) + \n",
      "      ' value: ' + str(values[min_rsme_value_index]))\n",
      "\n",
      "(min_kl_divergence_value_index, min_kl_divergence_value) = min(enumerate(validate_errors_list[:,1]), key=itemgetter(1))\n",
      "print('minimum kl_divergence: ' + str(min_kl_divergence_value) + \n",
      "      ' value: ' + str(values[min_kl_divergence_value_index]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}