{
 "metadata": {
  "name": "",
  "signature": "sha256:5253e5f20e09baf7329490943ba70bfad820a133b5a84a8bfe12f79dd86bcf93"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import (tree, ensemble, metrics, dummy)\n",
      "from sklearn.linear_model import Lasso\n",
      "\n",
      "from galaxy_data import GalaxyData\n",
      "import evaluate\n",
      "import feature_extraction\n",
      "import matplotlib.pyplot as plt \n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from multiprocessing import Pool \n",
      "from operator import itemgetter "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 151
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = GalaxyData(feature_extraction.hog_features, scale_features=False)\n",
      "(X_train, y_train, X_validate, y_validate) = data.split_training_and_validation_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading: ../../data/proc_images/hog_features/feature_vectors_training\n"
       ]
      }
     ],
     "prompt_number": 152
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_errors(input_data):\n",
      "    (values, X_train, y_train, X_validate, y_validate) = input_data\n",
      "    clf = tree.DecisionTreeRegressor(min_samples_split=values)\n",
      "    #clf = ensemble.RandomForestRegressor(max_features='log2', min_samples_split=values)\n",
      "    clf = ensemble.RandomForestRegressor(max_features='log2', n_estimators=values)\n",
      "    clf.fit(X_train, y_train)\n",
      "    validate_errors = evaluate.get_errors_clf(clf, X_validate, y_validate)\n",
      "    training_errors = evaluate.get_errors_clf(clf, X_train, y_train)\n",
      "    return (validate_errors, training_errors)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Decision tree min_samples_split\n",
      "values = range(2, 10000, 100)\n",
      "\n",
      "# Random Forest min_samples_split\n",
      "#values = range(2, 1000, 1)\n",
      "\n",
      "# Random Forest n_estimators\n",
      "#values = range(1, 100)\n",
      "\n",
      "pool = Pool()\n",
      "input_data_list = [(x, X_train, y_train, X_validate, y_validate) for x in values]\n",
      "output = np.array(pool.map(get_errors, input_data_list))\n",
      "validate_errors_list = output[:,0]\n",
      "training_errors_list = output[:,1]\n",
      "\n",
      "pool.close()\n",
      "pool.join()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "min_samples_split_list = range(2, 1000, 100)\n",
      "dr = dummy.DummyRegressor()\n",
      "dr.fit(X_train, y_train)\n",
      "base_line_error = evaluate.get_errors_clf(dr, X_validate, y_validate)\n",
      "base_line_error_list = [base_line_error for x in values]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def resolve_errors_lists(errors_list):\n",
      "    rmse = [x[0] for x in errors_list]\n",
      "    kl_divergence = [x[1] for x in errors_list]\n",
      "    kl_divergence = [x if x != float('Inf') else 0.25 for x in kl_divergence]\n",
      "    return (rmse, kl_divergence)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_data(values, validate_errors_list, training_errors_list, base_line_error_list):\n",
      "    # Setup error types\n",
      "    error_types = ['rmse', 'KL divergence']\n",
      "    validation_errors = resolve_errors_lists(validate_errors_list)\n",
      "    training_errors = resolve_errors_lists(training_errors_list)\n",
      "    base_line_errors = resolve_errors_lists(base_line_error_list)\n",
      "    \n",
      "    for (i, error_type) in enumerate(error_types):\n",
      "        plt.subplot(1, 2, i) \n",
      "        plt.plot(values, validation_errors[i], label='validation')\n",
      "        plt.plot(values, training_errors[i], label='training')\n",
      "        plt.plot(values, base_line_errors[i], label='baseline(mean)')\n",
      "        plt.plot()\n",
      "        plt.title('Training and Validation ' + error_type)\n",
      "        plt.legend(loc='right', bbox_to_anchor = (0.9, 0.3) )\n",
      "        plt.xlabel('number of trees')\n",
      "        plt.ylabel(error_type)\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_data(values, validate_errors_list, training_errors_list, base_line_error_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(min_rsme_value_index, min_rsme_value) = min(enumerate(validate_errors_list[:,0]), key=itemgetter(1))\n",
      "print('minimum rmse: ' + str(min_rsme_value) + \n",
      "      ' value: ' + str(values[min_rsme_value_index]))\n",
      "\n",
      "(min_kl_divergence_value_index, min_kl_divergence_value) = min(enumerate(validate_errors_list[:,1]), key=itemgetter(1))\n",
      "print('minimum kl_divergence: ' + str(min_kl_divergence_value) + \n",
      "      ' value: ' + str(values[min_kl_divergence_value_index]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
