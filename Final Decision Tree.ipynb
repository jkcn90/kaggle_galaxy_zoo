{
 "metadata": {
  "name": "",
  "signature": "sha256:a8c888f65b1fe58429e8cfd20146d25416f30cd52e551cde21bc8cad0b71579e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import (tree, ensemble, metrics, dummy)\n",
      "\n",
      "from galaxy_data import GalaxyData\n",
      "import evaluate\n",
      "import matplotlib.pyplot as plt \n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from multiprocessing import Pool "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = GalaxyData(scale_features=False)\n",
      "(X_train, y_train, X_validate, y_validate) = data.split_training_and_validation_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading: output_data/default/feature_vectors_training\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_errors(input_data):\n",
      "    (min_samples_split, X_train, y_train, X_validate, y_validate) = input_data\n",
      "    clf = tree.DecisionTreeRegressor(min_samples_split=min_samples_split)\n",
      "    clf.fit(X_train, y_train)\n",
      "    validate_errors = evaluate.get_errors_clf(clf, X_validate, y_validate)\n",
      "    training_errors = evaluate.get_errors_clf(clf, X_train, y_train)\n",
      "    return (validate_errors, training_errors)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "min_samples_split_list = range(2, 5000, 100)\n",
      "\n",
      "pool = Pool()\n",
      "input_data_list = [(x, X_train, y_train, X_validate, y_validate) for x in min_samples_split_list]\n",
      "output = np.array(pool.map(get_errors, input_data_list))\n",
      "validate_errors_list = output[:,0]\n",
      "training_errors_list = output[:,1]\n",
      "\n",
      "pool.close()\n",
      "pool.join()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dr = dummy.DummyRegressor()\n",
      "dr.fit(X_train, y_train)\n",
      "base_line_error = evaluate.get_errors_clf(dr, X_validate, y_validate)\n",
      "base_line_error_list = [base_line_error for x in min_samples_split_list]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def resolve_errors_lists(errors_list):\n",
      "    rmse = [x[0] for x in errors_list]\n",
      "    kl_divergence = [x[1] for x in errors_list]\n",
      "    return (rmse, kl_divergence)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_data(validate_errors_list, training_errors_list, base_line_error_list):\n",
      "    # Setup error types\n",
      "    error_types = ['rmse', 'KL divergence']\n",
      "    validation_errors = resolve_errors_lists(validate_errors_list)\n",
      "    training_errors = resolve_errors_lists(training_errors_list)\n",
      "    base_line_errors = resolve_errors_lists(base_line_error_list)\n",
      "    \n",
      "    for (i, error_type) in enumerate(error_types):\n",
      "        plt.subplot(1, 2, i) \n",
      "        plt.plot(min_samples_split_list, validation_errors[i], label='validation')\n",
      "        plt.plot(min_samples_split_list, training_errors[i], label='training')\n",
      "        plt.plot(min_samples_split_list, base_line_errors[i], label='baseline(mean)')\n",
      "        plt.plot()\n",
      "        plt.title('Training and Validation ' + error_type)\n",
      "        plt.legend(loc='best')\n",
      "        plt.xlabel('min_samples_split')\n",
      "        plt.ylabel(error_type)\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_data(validate_errors_list, training_errors_list, base_line_error_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.array(validate_errors_list[:,0]) == 0.1942221433831624"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 63,
       "text": [
        "array([False, False, False, False,  True, False, False, False, False,\n",
        "       False, False, False, False, False, False, False, False, False,\n",
        "       False, False, False, False, False, False, False, False, False,\n",
        "       False, False, False, False, False, False, False, False, False,\n",
        "       False, False, False, False, False, False, False, False, False,\n",
        "       False, False, False, False, False], dtype=bool)"
       ]
      }
     ],
     "prompt_number": 63
    }
   ],
   "metadata": {}
  }
 ]
}